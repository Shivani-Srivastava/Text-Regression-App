---
title: "Text regression funcs for shiny app"
output:
  html_document:
    df_print: paged
---

Below is code to functionize a text-regression (OLS) on datasets which contain a mix of regular variable columns and text columns (e.g., reviews).

Unlike the classification app, this one uses OLS to fit a model to metric Y.

Idea is as follows. We construct a data frame `df0` which has a metric `y`, some regular `X` variables - both metric and factor, as well as a text-column reduced to DTM form - all column bound together. 

To get the DTM, I use tidytext and code 3 routines to help. The rest is straightforward.

P.S. For tractability reasons, we restrict the size of the DTM used in the regression.

### App layout

Follows the Text classification app closely.

* UI has the following:
  - csv file input field
  - select metric Y variable (dropdown)
  - select X variables (variable selection)
  - select text column  (dropdown)
  - Training sample proportion (slider, default=0.70)
  
  - The following are UIs in the DTM construction tab
  - TF vs TFIDF (dropdown)
  - min_occurrence  (slider from 0 to 70%)
  - max_occurrence  (slider from 50 to 100%)
  - number of terms  (default = 250, slider or entry field from 10 to 1000)


* Output tabs have following structure
  - Intro and Overview
  - Data summary (show top 10 or 15 rows of dataset, and str(data))
  - DTM construction (show full dtm size, 10x10 DTM slice as HTML tbl, downloadable)
  - Regression results (Training coeff table as HTML, downloadable, test sample RMSE)
  
That's it for now. May even drop the requirement for training and test given time constraints.  

```{r setup}
suppressPackageStartupMessages({
  
  require(tidyverse)
  require(tidytext)
  require(stringr)
  require(Matrix)	
  
})
```

### Intermediate routines defined

3 are needed. App takes time ~ 1 min types.

```{r def_routines}

# +++ defining a purely clean_text op
clean_text <- function(text, lower=FALSE, alphanum=FALSE, drop_num=FALSE){
  text  =  str_replace_all(text, "<.*?>", " ")   # drop html junk
  
  if (lower=="TRUE") {text = text %>% str_to_lower()}
  if (alphanum=="TRUE") {text = text %>% str_replace_all("[^[:alnum:]]", " ")}
  if (drop_num=="TRUE") {text = text %>% str_replace_all("[:digit:]", "")}
  
  # collapse multiple spaces
  text = text %>%   
    str_replace_all("\\\\s+", " ")  
  
  return(text) } # clean_text() ends

### +++ new func to cast DTMs outta processed corpora +++ ###
casting_dtm <- function(text_as_df,    	 # text_as_df is single df colm 
                        tfidf=FALSE,     
                        use.stopwords=TRUE,    # whether to use stopwords at all 
                        additional.stopwords=NULL){ # any additional stopwords?
  
  ## tokenizing the corpus
  textdf1 = text_as_df %>% 
    mutate(docID = row_number()) %>%    # row_number() is v useful.    
    group_by(docID) %>%
    unnest_tokens(word, text) %>%
    count(word, sort = TRUE) %>% ungroup()
  
  ## make stop.words list
  stop.words = data.frame(word = as.character(unique(c(additional.stopwords, stop_words$word))),
                          stringsAsFactors=FALSE)	
  
  if (use.stopwords == "TRUE"){ textdf1 = textdf1 %>% anti_join(stop.words) }
  
  ## cast into a Matrix object
  if (tfidf == "TRUE") {
    textdf2 = textdf1 %>% group_by(docID) %>% 
      count(word, sort=TRUE) %>% ungroup() %>%
      bind_tf_idf(word, docID, n) %>% 
      rename(value = tf_idf)
  } else { 
      textdf2 = textdf1 %>% rename(value = n)  }
  
  m <- textdf2 %>% cast_sparse(docID, word, value); dim(m)
  
  # reorder dtm to have sorted rows by doc_num and cols by colsums	
  m = m[order(as.numeric(rownames(m))),]    # reorder rows	
  b0 = apply(m, 2, sum) %>% order(decreasing = TRUE)
  m = m[, b0]
  
  # anomaly handling
  m = as.matrix(m)
  a5 = seq(1:nrow(text_as_df))
  a6 = !(a5 %in% rownames(m)); length(a6); a6[1:5]
  a7 = matrix(0, nrow=sum(a6), ncol=ncol(m))
  rownames(a7) = which(a6)
  colnames(a7) = colnames(m)
  a8 = rbind(m, a7); dim(a8); 
  a9 = sort(as.numeric(rownames(a8)), decreasing=FALSE, index.return=TRUE)
  a8 = a8[a9$ix,]  # this is output. matrix
  
  return(a8) }    # func ends


### +++ new func to preprocess n prune DTMs +++ ###
preprocess_dtm <- function(dtm, min_occur = 0.02, max_occur = 0.95){
  
  a0 = apply(dtm, 2, sum) %>% as.numeric()
  min_thresh = quantile(a0, min_occur) %>% as.numeric(); min_thresh
  max_thresh = quantile(a0, max_occur) %>% as.numeric(); max_thresh
  a1 = (a0 > max_thresh | a0 < min_thresh); length(a1); sum(a1)
  dtm1 = dtm[,!a1]; dim(dtm1)
  return(dtm1)
  
} # func ends

```

### Demo on a dataset

Reading in a kickstarter dataset from kaggle. Will use only about 5k rows for demo purposes.

```{r data_load}

require(data.table)
#path0 = "D:\\Dropbox\\teaching related\\MLBM\\Co 2021\\datasets\\kickstarter projects\\"
ks = fread(paste0("tech_projs_with desc.csv"))

train_propn_ui = 0.70  # from U, slider

a00 = ks[1:10000,]  # using 10k rows for training

y = a00$pledged  # from UI

X = data.frame(category = a00$category, # from UI, variable selection
               goal = a00$goal, backers = a00$backers) 

text_colm_ui = a00$desc  # from UI, variable dropdown

num_terms_ui = 250   # from UI. slider from 50 to 500
min_occurrence_ui = 0.50
max_occurrence_ui = 0.99
tfidf_ui = TRUE

```


### DTM creation

Main func comes here with the data

```{r main_func}

# ' --- piping a workflow based on above 3 sourced funcs --- '

text_regn_main <- function(text_colm_ui, min_occurrence_ui, max_occurrence_ui, 
                           tfidf_ui)
  {

    my_dtm = text_colm_ui %>% tibble(text = .) %>% 
      
      map_dfr(., function(x) clean_text(x, lower=TRUE)) %>% 
      
      casting_dtm(tfidf=tfidf_ui) %>% 
    
      preprocess_dtm(min_occur = min_occurrence_ui, 
                     max_occur = max_occurrence_ui) %>% 
      
      as.data.frame()  # 58s # make a n x 2000 DF available for download?
    
  } # func ends
    

# test-drive
system.time({
my_dtm = text_regn_main(text_colm_ui, min_occurrence_ui, 
                        max_occurrence_ui, tfidf_ui)
})

```

Above object `my_dtm` feeds into a regular OLS regression. 

### Regression portion


```{r ols_final}

a0_ix = sample(seq(1:nrow(a00)), size = round(nrow(a00)*train_propn_ui,0))

a00_train = a00[a0_ix,]; dtm_train = my_dtm[a0_ix,]
a00_test = a00[!a0_ix,]; dtm_test = my_dtm[!a0_ix,]

# df0 is analysis DF from here
df0_train = data.frame(y=y[a0_ix], X[a0_ix,], dtm_train[,1:num_terms_ui])
df0_test = data.frame(X[!a0_ix,], dtm_test[,1:num_terms_ui]) 

# ' --- OLS on df0_train --- '

a0 = lm(y~., data=df0_train, na.rm=TRUE) # 1.8s for n=250

a1 = summary(a0)$coefficients  # display as HTML tbl and downloadable

head(a1, 15)

cat("\n, The R-square is: ", summary(a0)$r.squared, "\n")
cat("\n, The F-statistic is: ", summary(a0)$fstatistic, "\n")

```

Prediction on test_set can be seen too. See below.

```{r test_set_prediction}

# a2 = predict(a0, df0_test)

```


That's it. Could drop prediction on test sample as it is giving trouble, looks like.

Sudhir